{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b950cda7",
   "metadata": {},
   "source": [
    "# Imports and overview\n",
    "\n",
    "This notebook implements the CORAL model from https://arxiv.org/pdf/1511.05547.pdf. It is inspired from https://github.com/SSARCandy/DeepCORAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "144fa7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now load the dependencies\n",
    "%matplotlib inline \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6211a13b",
   "metadata": {},
   "source": [
    "We can start by setting a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "356ddda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd819240190>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6fe08f8",
   "metadata": {},
   "source": [
    "For reference, here is the architecture of the model we will implement:\n",
    "\n",
    "<img src=\"CORAL_architecture.png\" align=\"center\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8c3d84a",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9121b596",
   "metadata": {},
   "source": [
    "We start by defining a custom dataset which loads the data from disk lazily. This is because we have too many training examples to keep all of them in memory at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6afe02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to apply to the minibatches for data augmentation\n",
    "# Define the transformation to apply\n",
    "# Transformations: Random horizontal and vertical flips, halving and doubling the brightness\n",
    "# This should improve the prediction accuracy\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=[0.75, 1.25])], p=0.5)\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.images = os.listdir(root_dir)\n",
    "        self.labels = torch.load(label_dir).long()\n",
    "\n",
    "        # Remove the labels that do not belong to this split of the dataset (Labels is all labels)\n",
    "        self.labels = self.labels[torch.tensor([int(img_name[3:9]) for img_name in self.images])]\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        image = transform(image)\n",
    "        label = self.labels[idx] # Since we removed the labels that do not belong to this split, we can use idx directly\n",
    "        return image, label\n",
    "\n",
    "# Extract the generated data\n",
    "generated_data_root = \"../../Data Generation/Pre Processed Data Generated\"\n",
    "train_gen_dataset = CustomDataset(generated_data_root + \"/Square Images/Training\", generated_data_root + \"/Square Images/y_generated.pt\")\n",
    "val_gen_dataset = CustomDataset(generated_data_root + \"/Square Images/Validation\", generated_data_root + \"/Square Images/y_generated.pt\")\n",
    "test_gen_dataset = CustomDataset(generated_data_root + \"/Square Images/Testing\", generated_data_root + \"/Square Images/y_generated.pt\")\n",
    "\n",
    "# Extract the real data\n",
    "real_data_root = \"../../Real life data/Pre processed Real Life\"\n",
    "train_real_dataset = CustomDataset(real_data_root + \"/Square Images/Training\", real_data_root + \"/Square Images/y_real_life.pt\")\n",
    "val_real_dataset = CustomDataset(real_data_root + \"/Square Images/Validation\", real_data_root + \"/Square Images/y_real_life.pt\")\n",
    "test_real_dataset = CustomDataset(real_data_root + \"/Square Images/Testing\", real_data_root + \"/Square Images/y_real_life.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b93703ce",
   "metadata": {},
   "source": [
    "# Hyperparameter choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b259e4e1",
   "metadata": {},
   "source": [
    "We create a cell to hold the hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a6ce00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100 # Each the real and generated data will be split into batches of this size (Since we only train on generated here)\n",
    "num_epochs = 1 # Since we only train on generated data, we can use a small number of epochs because we have around 300000 images plus the augmentation\n",
    "dropout_rate_choices = {0.2, 0.5}\n",
    "gamma_focal_loss_choices = {2, 5} # Choices for the gamma parameter in the focal loss\n",
    "n_validation = 10 # Number of iterations between each validation run\n",
    "n_validation_minibatches = 2 # Number of minibatches to use for validation\n",
    "n_final_validation_minibatches = 20 # Number of minibatches to use for the final validation run\n",
    "lambda_coral_choices = {1, 0.5} # Regularization parameter for CORAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e60fc99",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "868ef8b6",
   "metadata": {},
   "source": [
    "We can start by loading a pre-trained VGG16 model without the classification layers towards the end (Only the feature extractor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1a976a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8433f526",
   "metadata": {},
   "source": [
    "We can now visualize its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9614fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "018e9568",
   "metadata": {},
   "source": [
    "Because we are looking for a pre-trained feature extractor here, we decide to only use the features part and freeze its weights. We can then add a few subsequent layers to fine tune predictions. We can thus define the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a051bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoralModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=13, dropout_rate=0.5):\n",
    "        \n",
    "        super(CoralModel, self).__init__()\n",
    "        \n",
    "        # Define the layers of the model\n",
    "        self.features = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1').features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4608, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Set the features to not require gradients\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7348424",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3c49179",
   "metadata": {},
   "source": [
    "We can start by finding the device to use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1237640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61cb4352",
   "metadata": {},
   "source": [
    "We can then go ahead and define the loss function we will be using. \n",
    "\n",
    "According to the specified model architecture, the CORAL model utilizes two loss functions. The first one is the classification loss, for whihc we will opt for a balanced focal loss rather than the regular cross-entropy loss. The aim is to assign greater importance to the classes that are more challenging to classify. The focal loss can be defined using the following formula:\n",
    "\n",
    "$$\n",
    "FL(p_t) = -(1-p_t^{\\gamma})log(p_t)\n",
    "$$\n",
    "\n",
    "where gamma $\\gamma$ is a tunable hyperparameter. We can also further add an alpha term to handle class imbalance, making our loss function a class-balanced focal loss, as shown in https://github.com/AdeelH/pytorch-multi-class-focal-loss. \n",
    "Note: Since we have balanced classes thanks to oversmapling, we will not use the alpha parameter.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "304c6a68",
   "metadata": {},
   "source": [
    "The second loss is the Coral loss. Coral loss is a type of distance metric used to align two sets of feature representations. It stands for \"correlation alignment\".\n",
    "\n",
    "The Coral loss aims to minimize the domain shift between two distributions by aligning the second-order statistics of their features. It computes the covariance matrix of the source and target features and then minimizes the Frobenius norm between the difference of the two covariance matrices. This way, the correlation between the features is preserved and domain shift is reduced.\n",
    "\n",
    "The Coral loss can be formulated as:\n",
    "\n",
    "$$\n",
    "L_{coral}(X_s, X_t) = \\lVert C_s - C_t \\rVert_{F}^2\n",
    "$$\n",
    "\n",
    "where $X_s$ and $X_t$ are the source and target feature representations respectively, and $C_s$ and $C_t$ are the covariance matrices of the source and target features.\n",
    "\n",
    "In addition to the loss function, a helper function can be defined to compute the covariance matrix:\n",
    "\n",
    "$$\n",
    "C(X) = \\frac{1}{n-1}(X-\\bar{X})^T(X-\\bar{X})\n",
    "$$\n",
    "\n",
    "where $X$ is a matrix of feature representations and $\\bar{X}$ is the mean of each feature. The following code is taken from the mentionned github repository: https://github.com/SSARCandy/DeepCORAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "734c90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CORAL(source, target):\n",
    "#     d = source.data.shape[1]\n",
    "\n",
    "#     # source covariance\n",
    "#     xm = torch.mean(source, 0, keepdim=True) - source\n",
    "#     xc = xm.t() @ xm\n",
    "\n",
    "#     # target covariance\n",
    "#     xmt = torch.mean(target, 0, keepdim=True) - target\n",
    "#     xct = xmt.t() @ xmt\n",
    "\n",
    "#     # frobenius norm between source and target\n",
    "#     loss = torch.mean(torch.mul((xc - xct), (xc - xct)))\n",
    "#     loss = loss/(4*d*d)\n",
    "\n",
    "#     return loss\n",
    "\n",
    "def CORAL(source_features, target_features):\n",
    "    source_cov = torch.matmul(source_features.T, source_features)\n",
    "    target_cov = torch.matmul(target_features.T, target_features)\n",
    "    loss = torch.mean(torch.square(source_cov - target_cov))\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ecaecd",
   "metadata": {},
   "source": [
    "The total loss used in the backward step of our model is therefore represented by the following equation:\n",
    "\n",
    "$$\n",
    "TotalLoss = ClassificationLoss + \\lambda DomainLoss\n",
    "$$\n",
    "$$\n",
    "TotalLoss = FC + \\lambda L_{coral}(X_s, X_t)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e28a4adc",
   "metadata": {},
   "source": [
    "We also adjust the hyperparameter $\\lambda$, which determines the weight of the coral loss term in the total loss function.\" In other words, $\\lambda$ controls the contribution of the coral loss to the overall loss value, with larger values of $\\lambda$ giving the coral loss term more weight in the optimization process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "057bb473",
   "metadata": {},
   "source": [
    "Finally, we need an accuracy metric to tune the hyperparameters of the model. We will opt for a balanced accuracy score, which is just regular classification accuracy but adapted to weigh each class by its frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c3ba9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=13, average=\"weighted\").to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2047f74c",
   "metadata": {},
   "source": [
    "Finally, because we are using balanced accuracy scores, we can use the class analytics gathered during pre-processing to define the following class distribution array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "36161b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0001\n",
      "0.9998999999999999\n"
     ]
    }
   ],
   "source": [
    "class_proportions_gen = np.array([0.3198, 0.1602, 0.0405, 0.0400, 0.0406, 0.0201, 0.0404, 0.1596, 0.0392, 0.0397, 0.0400, 0.0196, 0.0404])\n",
    "class_proportions_real = np.array([0.3228, 0.1738, 0.0347, 0.0415, 0.0454, 0.0206, 0.0354, 0.1490, 0.0284, 0.0463, 0.0432, 0.0234, 0.0354])\n",
    "\n",
    "# Print the sum of the class proportions as a sanity check\n",
    "print(class_proportions_gen.sum())\n",
    "print(class_proportions_real.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1e13081",
   "metadata": {},
   "source": [
    " We can now proceed to defining a function that creates a data loader for both datasets, oversampling the minority classes and applying horizontal flip and blur transformations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad76b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loader(dataset, batch_size):\n",
    "\n",
    "    # Define the sampler\n",
    "    class_weights = 1. / torch.tensor(class_proportions_gen, dtype=torch.float) # The weights of the classes\n",
    "    sample_weights = class_weights[dataset.labels] # Assign each label its corresponding weight\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "def get_real_loader(dataset, batch_size):\n",
    "\n",
    "    # Define the sampler\n",
    "    class_weights = 1. / torch.tensor(class_proportions_real, dtype=torch.float) # The weights of the classes\n",
    "    sample_weights = class_weights[dataset.labels] # Assign each label its corresponding weight\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ad6b2b4",
   "metadata": {},
   "source": [
    "We can now load a single example from the loader and display its label as well as its class proportion, which should be around 1/13 which is +- 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "82f2ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_train_loader = get_gen_loader(train_gen_dataset, batch_size=200)\n",
    "\n",
    "for i, (images, labels) in enumerate(gen_train_loader):\n",
    "    class_proportions = [(labels == i).sum() / len(labels) for i in range(13)]\n",
    "    plt.title(\"label: \" + str(labels[0].item()) + \" proportion: \" + str(class_proportions[labels[0].item()].item() * 100) + \"%\")\n",
    "    plt.imshow(images[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fa0629a",
   "metadata": {},
   "source": [
    "We can also define the following function for plotting the metrics collected during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "162e9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_metrics(gen_training_losses, class_losses, domain_losses, gen_training_accs, gen_training_f1s, gen_validation_losses, gen_validation_accs, gen_validation_f1s, real_validation_losses, real_validation_accs, real_validation_f1s, gamma, batch_size, dropout_rate):\n",
    "\n",
    "    validation_x_axis = np.arange(0, len(gen_validation_losses) * n_validation, n_validation)\n",
    "\n",
    "    plt.figure(figsize=(30, 30))\n",
    "\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(gen_training_losses, label=\"Total Loss\")\n",
    "    plt.plot(class_losses, label=\"Classification Loss\")\n",
    "    plt.plot(domain_losses, label=\"Domain Loss\")\n",
    "    plt.title(\"Training Losses (Total, Classification and Domain Losses)\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(gen_training_accs)\n",
    "    plt.title(\"Training Accuracies\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(gen_training_f1s)\n",
    "    plt.title(\"Training weighted F1 scores\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Weighted F1 score\")\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(validation_x_axis, gen_validation_losses, label=\"Source domain\")\n",
    "    plt.plot(validation_x_axis, real_validation_losses, label=\"Target domain\")\n",
    "    plt.title(\"Validation Losses\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Focal loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(validation_x_axis, gen_validation_accs, label=\"Source domain\")\n",
    "    plt.plot(validation_x_axis, real_validation_accs, label=\"Target domain\")\n",
    "    plt.title(\"Validation Accuracies\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.plot(validation_x_axis, gen_validation_f1s, label=\"Source domain\")\n",
    "    plt.plot(validation_x_axis, real_validation_f1s, label=\"Target domain\")\n",
    "    plt.title(\"Validation weighted F1 Scores\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Weighted F1 Score\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(\"Hyperparameters: gamma: \" + str(gamma) + \", batch_size: \" + str(batch_size) + \", dropout_rate: \" + str(dropout_rate), fontsize=24)\n",
    "    \n",
    "    plt.savefig(\"HP tuning results/\" + \"gamma_\" + str(gamma) + \"_batch_\" + str(batch_size) + \"_dropout_\" + str(dropout_rate) + \".png\",  facecolor='white', transparent=False)\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e0fb873",
   "metadata": {},
   "source": [
    "We can now proceed to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "02e90133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/893 [01:34<23:29:09, 94.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "EPOCH [1], ITERATION [1]\n",
      "TRAINING => Total Loss: 2.193307876586914, Classification Loss: 2.1906540393829346, CORAL loss: 0.005307438783347607, Training accuracy: 0.07999999076128006, Training weighted F1: 0.05799185484647751\n",
      "GENERATED VALIDATION => Loss: 2.074993133544922, Validation accuracy: 0.17499999701976776, Validation weighted F1: 0.09228627383708954\n",
      "REAL VALIDATION => Loss: 2.182999610900879, Validation accuracy: 0.06499999761581421, Validation weighted F1: 0.024961411952972412\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/893 [07:28<12:53:45, 52.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "EPOCH [1], ITERATION [10]\n",
      "TRAINING => Total Loss: 2.0820584297180176, Classification Loss: 2.0324716567993164, CORAL loss: 0.099173404276371, Training accuracy: 0.25999999046325684, Training weighted F1: 0.18926988542079926\n",
      "GENERATED VALIDATION => Loss: 2.0567946434020996, Validation accuracy: 0.30000001192092896, Validation weighted F1: 0.21208830177783966\n",
      "REAL VALIDATION => Loss: 2.0992820262908936, Validation accuracy: 0.23000000417232513, Validation weighted F1: 0.15463003516197205\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 18/893 [11:49<8:19:56, 34.28s/it] "
     ]
    }
   ],
   "source": [
    "# To store the best model\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "# Store the validation accuracies\n",
    "hp_final_accs = pd.DataFrame(columns=[\"Gamma\", \"Batch size\", \"Dropout rate\", \"Final validation accuracy\"])\n",
    "\n",
    "for gamma in gamma_focal_loss_choices:\n",
    "\n",
    "    for dropout_rate in dropout_rate_choices:\n",
    "\n",
    "        for lambda_coral in lambda_coral_choices:\n",
    "            # Define the data loaders accounting for the batch size\n",
    "            gen_train_loader = get_gen_loader(train_gen_dataset, batch_size=batch_size)\n",
    "            gen_val_loader = get_gen_loader(val_gen_dataset, batch_size=batch_size)\n",
    "            gen_test_loader = get_gen_loader(test_gen_dataset, batch_size=batch_size)\n",
    "            real_train_loader = get_real_loader(train_real_dataset, batch_size=batch_size)\n",
    "            real_val_loader = get_real_loader(val_real_dataset, batch_size=batch_size)\n",
    "            real_test_loader = get_real_loader(test_real_dataset, batch_size=batch_size)\n",
    "\n",
    "            # Define the new loss function (Taking into account gamma)\n",
    "            focal_loss = torch.hub.load(\n",
    "                'adeelh/pytorch-multi-class-focal-loss',\n",
    "                model='FocalLoss',\n",
    "                gamma=gamma, # No use of alpha since we have balanced classes now with the oversampling\n",
    "                reduction='mean',\n",
    "                force_reload=False,\n",
    "                verbose = False\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            # To store the metrics through epochs\n",
    "            gen_training_losses = []\n",
    "            gen_training_accs = []\n",
    "            gen_training_f1s = []\n",
    "            gen_validation_losses = []\n",
    "            gen_validation_accs = []\n",
    "            gen_validation_f1s = []\n",
    "            real_validation_losses = []\n",
    "            real_validation_accs = []\n",
    "            real_validation_f1s = []\n",
    "            class_losses = []\n",
    "            domain_losses = []\n",
    "\n",
    "            # Define the model and the optimizer\n",
    "            coralmodel = CoralModel(dropout_rate=dropout_rate).to(DEVICE)\n",
    "            opt = optim.Adam(coralmodel.parameters(), lr=learning_rate)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                \n",
    "                # Train the model\n",
    "                for iteration, ((X_train_gen, y_train_gen), (X_train_real, _)) in tqdm(enumerate(zip(gen_train_loader, real_train_loader)), total=len(gen_train_loader)):\n",
    "                    \n",
    "                    # Set the model to training mode\n",
    "                    coralmodel.train()\n",
    "\n",
    "                    # Move the data to the device\n",
    "                    X_train_gen = X_train_gen.to(DEVICE)\n",
    "                    y_train_gen = y_train_gen.to(DEVICE)\n",
    "\n",
    "                    # Forward pass for source data (Generated data)\n",
    "                    y_train_pred_raw_gen = coralmodel(X_train_gen)\n",
    "                    y_train_pred_gen = torch.argmax(y_train_pred_raw_gen, dim=1)\n",
    "\n",
    "                    # Forward pass for target data (Real data)\n",
    "                    y_train_pred_raw_real = coralmodel(X_train_real)\n",
    "                    y_train_pred_real = torch.argmax(y_train_pred_raw_real, dim=1)\n",
    "\n",
    "                    # Compute the classification loss (Focal loss)\n",
    "                    loss_train = focal_loss(y_train_pred_raw_gen, y_train_gen.long())\n",
    "\n",
    "                    # Compute the domain loss (CORAL loss)\n",
    "                    domain_loss = CORAL(y_train_pred_raw_gen, y_train_pred_raw_real)\n",
    "\n",
    "                    # Get the total loss\n",
    "                    total_loss = loss_train + lambda_coral * domain_loss\n",
    "\n",
    "                    # Compute the accuracy\n",
    "                    acc_train = accuracy(y_train_pred_gen, y_train_gen)\n",
    "                    f1_train = f1_score(y_train_pred_gen, y_train_gen)\n",
    "\n",
    "                    # Backward pass\n",
    "                    opt.zero_grad()\n",
    "                    total_loss.backward()\n",
    "                    opt.step()\n",
    "\n",
    "                    # Store the loss & accuracy\n",
    "                    gen_training_losses.append(total_loss.item())\n",
    "                    gen_training_accs.append(acc_train.item())\n",
    "                    gen_training_f1s.append(f1_train.item())\n",
    "                    \n",
    "                    # Store corresponding class and domain losses\n",
    "                    class_losses.append(loss_train.item())\n",
    "                    domain_losses.append(domain_loss.item())\n",
    "                    \n",
    "                    # Check if the model should be validated\n",
    "                    if iteration == 0 or (iteration + 1) % n_validation == 0:\n",
    "                        \n",
    "                        # Set the model to evaluation mode\n",
    "                        coralmodel.eval()\n",
    "                        \n",
    "                        # Disable gradient calculation\n",
    "                        with torch.no_grad():\n",
    "\n",
    "                            # 1) Evaluate on the generated validation set\n",
    "                            acc_val_sum = 0\n",
    "                            weighted_f1_val_sum = 0\n",
    "                            loss_val_sum = 0\n",
    "\n",
    "                            # Extract an iterator from the generated data loader\n",
    "                            gen_val_iter = iter(gen_val_loader)\n",
    "\n",
    "                            # Iterate for n_validation_minibatches\n",
    "                            for i in range(n_validation_minibatches):\n",
    "\n",
    "                                # Get the next minibatch\n",
    "                                X_val_gen, y_val_gen = next(gen_val_iter)\n",
    "                                    \n",
    "                                # Move the data to the device\n",
    "                                X_val_gen = X_val_gen.to(DEVICE)\n",
    "                                y_val_gen = y_val_gen.to(DEVICE)\n",
    "\n",
    "                                # Forward pass\n",
    "                                y_val_pred_raw_gen = coralmodel(X_val_gen)\n",
    "                                y_val_pred_gen = torch.argmax(y_val_pred_raw_gen, dim=1)\n",
    "\n",
    "                                # Compute the metrics\n",
    "                                acc_val_sum += accuracy(y_val_pred_gen, y_val_gen)\n",
    "                                weighted_f1_val_sum += f1_score(y_val_pred_gen, y_val_gen)\n",
    "                                loss_val_sum += focal_loss(y_val_pred_raw_gen, y_val_gen)\n",
    "\n",
    "                            # Compute the average metrics\n",
    "                            acc_val_gen = acc_val_sum / n_validation_minibatches\n",
    "                            loss_val_gen = loss_val_sum / n_validation_minibatches\n",
    "                            weighted_f1_val_gen = weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "                            # 2) Repeat on the real validation set\n",
    "                            acc_val_sum = 0\n",
    "                            weighted_f1_val_sum = 0\n",
    "                            loss_val_sum = 0\n",
    "\n",
    "                            # Extract an iterator from the generated data loader\n",
    "                            real_val_iter = iter(real_val_loader)\n",
    "\n",
    "                            # Iterate for n_validation_minibatches\n",
    "                            for i in range(n_validation_minibatches):\n",
    "\n",
    "                                # Get the next minibatch\n",
    "                                X_val_real, y_val_real = next(real_val_iter)\n",
    "                                    \n",
    "                                # Move the data to the device\n",
    "                                X_val_real = X_val_real.to(DEVICE)\n",
    "                                y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "                                # Forward pass\n",
    "                                y_val_pred_raw_real = coralmodel(X_val_real)\n",
    "                                y_val_pred_real = torch.argmax(y_val_pred_raw_real, dim=1)\n",
    "\n",
    "                                # Compute the metrics\n",
    "                                acc_val_sum += accuracy(y_val_pred_real, y_val_real)\n",
    "                                weighted_f1_val_sum += f1_score(y_val_pred_real, y_val_real)\n",
    "                                loss_val_sum += focal_loss(y_val_pred_raw_real, y_val_real)\n",
    "\n",
    "                            # Compute the average metrics\n",
    "                            acc_val_real = acc_val_sum / n_validation_minibatches\n",
    "                            loss_val_real = loss_val_sum / n_validation_minibatches\n",
    "                            weighted_f1_val_real = weighted_f1_val_sum / n_validation_minibatches\n",
    "\n",
    "                            # Store all 6 metrics\n",
    "                            gen_validation_losses.append(loss_val_gen.item())\n",
    "                            gen_validation_accs.append(acc_val_gen.item())\n",
    "                            gen_validation_f1s.append(weighted_f1_val_gen.item())\n",
    "                            real_validation_losses.append(loss_val_real.item())\n",
    "                            real_validation_accs.append(acc_val_real.item())\n",
    "                            real_validation_f1s.append(weighted_f1_val_real.item())\n",
    "\n",
    "                            # Print an update\n",
    "                            print('----------------------------------------------------------------')\n",
    "                            print(f'EPOCH [{epoch + 1}], ITERATION [{iteration+1}]')\n",
    "                            print(f'TRAINING => Total Loss: {total_loss}, Classification Loss: {loss_train}, CORAL loss: {domain_loss}, Training accuracy: {acc_train}, Training weighted F1: {f1_train}')\n",
    "                            print(f'GENERATED VALIDATION => Loss: {loss_val_gen}, Validation accuracy: {acc_val_gen}, Validation weighted F1: {weighted_f1_val_gen}')\n",
    "                            print(f'REAL VALIDATION => Loss: {loss_val_real}, Validation accuracy: {acc_val_real}, Validation weighted F1: {weighted_f1_val_real}')\n",
    "                            print('----------------------------------------------------------------')\n",
    "\n",
    "                # Save the model every epoch as a checkpoint \n",
    "                torch.save(coralmodel.state_dict(), f'./checkpoints/coralmodel_gamma_{gamma}_dropout_{dropout_rate}_batch_{batch_size}_epoch_{epoch+1}.ckpt')\n",
    "\n",
    "\n",
    "            # Evaluate the final real life validation accuracy\n",
    "\n",
    "            # Set the model to evaluation mode\n",
    "            coralmodel.eval()\n",
    "            acc_val_sum = 0\n",
    "\n",
    "            # Create an iterator\n",
    "            real_val_iter = iter(real_val_loader)\n",
    "\n",
    "            # Disable gradient calculation\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                for i in range(n_final_validation_minibatches):\n",
    "\n",
    "                    # Get the next minibatch\n",
    "                    minibatch = next(real_val_iter, None)\n",
    "                    if minibatch is None:\n",
    "                        real_val_iter = iter(real_val_loader)\n",
    "                        minibatch = next(real_val_iter, None)\n",
    "                    X_val_real, y_val_real = minibatch\n",
    "\n",
    "                    # Move the data to the device\n",
    "                    X_val_real = X_val_real.to(DEVICE)\n",
    "                    y_val_real = y_val_real.to(DEVICE)\n",
    "\n",
    "                    # Forward pass\n",
    "                    y_val_pred_prob_real = coralmodel(X_val_real)\n",
    "                    y_val_pred_real = torch.argmax(y_val_pred_prob_real, dim=1)\n",
    "\n",
    "                    # Compute the metrics\n",
    "                    acc_val_sum += accuracy(y_val_pred_real, y_val_real)\n",
    "\n",
    "            # Compute the average accuracy\n",
    "            final_real_val_acc = acc_val_sum / n_final_validation_minibatches\n",
    "\n",
    "            # Create a row to add to the dataframe\n",
    "            row = [gamma, batch_size, dropout_rate, final_real_val_acc.cpu().item()]\n",
    "\n",
    "            # Store it\n",
    "            hp_final_accs.loc[len(hp_final_accs)] = row\n",
    "\n",
    "            # Compare to the best model\n",
    "            if best_model is None or best_acc < final_real_val_acc:\n",
    "                best_model = coralmodel\n",
    "                best_acc = final_real_val_acc\n",
    "                torch.save(coralmodel.state_dict(), f'./best_model.ckpt')\n",
    "\n",
    "            # Plot and save the metrics\n",
    "            plot_and_save_metrics(gen_training_losses, class_losses, domain_losses, gen_training_accs, gen_training_f1s, gen_validation_losses, gen_validation_accs, gen_validation_f1s, real_validation_losses, real_validation_accs, real_validation_f1s, gamma, batch_size, dropout_rate)\n",
    "\n",
    "# Save the dataframe as a table\n",
    "hp_final_accs.to_csv('HP_final_accuracies.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64e5fcf3",
   "metadata": {},
   "source": [
    "After this code runs, the best model can be found in the directory of the script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
